{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f66e8c11-6c7d-48d5-b68f-047a0791f75c",
   "metadata": {},
   "source": [
    "# pyllms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b3c9b15-82b9-4431-8fb9-8ed46fc76fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59aaca5a-d69d-48a0-9c1e-73acd7f9a1e1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "model = llms.init('gpt-4')\n",
    "result = model.complete(\"what is 5+5\")\n",
    "\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675c4668-0cec-4da0-97b6-c2a5710f6e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gpt-4', 'tokens': 14, 'tokens_prompt': 13, 'tokens_completion': 1, 'cost': 0.00045, 'latency': 0.81}\n"
     ]
    }
   ],
   "source": [
    "print(result.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f18f6ae3-6cbc-4c58-807c-fc11469842a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.complete(\n",
    "    \"what is the capital of country where mozzart was born\",\n",
    "    temperature=0.1,\n",
    "    #temperature=1.1,\n",
    "    max_tokens=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d060018e-3ed2-4d8a-80e9-29ade8cf3745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the country where Mozart was born is Vienna. Mozart was born in Salzburg, Austria, but the capital of Austria is Vienna.\n",
      "{'model': 'gpt-4', 'tokens': 48, 'tokens_prompt': 19, 'tokens_completion': 29, 'cost': 0.00231, 'latency': 1.88}\n"
     ]
    }
   ],
   "source": [
    "print(result.text)\n",
    "print(result.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d4e7587-cbed-465c-a5b4-28000cedcb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f5739e5-5c16-4d4a-8ff7-90901fa6db1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# _meta\n",
      "  {'tokens_prompt': 19, 'tokens_completion': 29, 'latency': 1.87, 'cost': 0.00231}\n",
      "# cost\n",
      "  0.00231\n",
      "# function_call\n",
      "  {}\n",
      "# meta\n",
      "  {'model': 'gpt-4', 'tokens': 48, 'tokens_prompt': 19, 'tokens_completion': 29, 'cost': 0.00231, 'latency': 1.87}\n",
      "# model_inputs\n",
      "  {'messages': [{'role': 'user', 'content': 'what is the capital of country where mozzart was born'}], 'temperature': 0.1, 'max_tokens': 200, 'stream': False}\n",
      "# provider\n",
      "  OpenAIProvider('gpt-4')\n",
      "# text\n",
      "  The capital of the country where Mozart was born is Vienna. Mozart was born in Salzburg, Austria, but Vienna is the capital of Austria.\n",
      "# tokens\n",
      "  48\n",
      "# tokens_completion\n",
      "  29\n",
      "# tokens_prompt\n",
      "  19\n"
     ]
    }
   ],
   "source": [
    "var_names = [\n",
    "     '_meta',\n",
    "     'cost',\n",
    "     'function_call',\n",
    "     'meta',\n",
    "     'model_inputs',\n",
    "     'provider',\n",
    "     'text',\n",
    "     #'to_json',\n",
    "     'tokens',\n",
    "     'tokens_completion',\n",
    "     'tokens_prompt']\n",
    "for var_name in var_names:\n",
    "    print(\"# %s\\n  %s\" % (var_name, getattr(result, var_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec00efa-0739-4cbe-a5c4-0b835b36c33b",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e8f791-9df2-444d-b604-37841d587aa5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.36.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e3a1a57-05f4-4466-88b6-44883a6a1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54f81666-908c-4285-bc2e-7626a90072d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9nyGyYCcQUYTWC3D8IZhVWXszus7n', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In a land where code does twirl and spin,  \\nLives a curious creature—recursion within.  \\nA function that calls itself with glee,  \\nUnraveling puzzles, as clever as can be.  \\n\\nImagine a mirror reflecting a mirror's face,  \\nInfinite echoes in a recursive embrace.  \\nA task laid before it, a problem to solve,  \\nBut first, it must think, and then it evolves.  \\n\\n“Divide and conquer” is its guiding creed,  \\nBreaking down chaos into parts it can heed.  \\nWith each little call, it steps down the trail,  \\nOn a journey to find—it will not fail.  \\n\\nBase case, dear friend, is where it must cease,  \\nThe anchor of reason, the source of our peace.  \\nFor without it, you’d spiral, forever amiss,  \\nA looping adventure, a coder’s abyss.  \\n\\nLike a staircase winding up into the sky,  \\nIt climbs higher and higher, each step drawing nigh.  \\nWith each call, it stacks those calls on a heap,  \\nRemembering the past before diving deep.  \\n\\nWhen at last the goal is within its clear sight,  \\nIt begins to return, spreading knowledge like light.  \\nWith answers in tow, the stack unwinds slow,  \\nEach layer revealing the path it must go.  \\n\\nThus, recursion, dear coder, is both potent and great,  \\nA dance of a function, through time it will skate.  \\nSo when faced with a challenge, let it take flight,  \\nEmbrace sweet recursion, and code through the night!  \", role='assistant', function_call=None, tool_calls=None))], created=1721696788, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_661538dc1f', usage=CompletionUsage(completion_tokens=322, prompt_tokens=39, total_tokens=361))\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dd5076d-e1ec-46a1-9e80-3a937bb2750c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_check_frozen', '_copy_and_set_values', '_get_value', '_iter', 'choices', 'construct', 'copy', 'created', 'dict', 'from_orm', 'id', 'json', 'model', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'object', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'service_tier', 'system_fingerprint', 'to_dict', 'to_json', 'update_forward_refs', 'usage', 'validate']\n"
     ]
    }
   ],
   "source": [
    "print(dir(completion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87533a96-772c-40a0-9d4c-cb25000437b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of code where logic entwines,  \n",
      "Lives a concept, graceful, through layer it shines.  \n",
      "A dance of function, in echo, it speaks,  \n",
      "Meet recursion, the art that geeks seek.  \n",
      "\n",
      "A call to oneself, a mirror's embrace,  \n",
      "Where solutions emerge from a self-repeating space.  \n",
      "The base case, the anchor, keeps chaos at bay,  \n",
      "Without it, dear coder, you'll wander astray.  \n",
      "\n",
      "Imagine a staircase, each step leads to more,  \n",
      "You climb higher and higher, through each open door.  \n",
      "But to find the solution, you must first take a glance,  \n",
      "At the single step down, in this intricate dance.  \n",
      "\n",
      "A factorial's example, both simple and bright,  \n",
      "Five factorial whispers, \"It's four times my might!\"  \n",
      "And four calls upon three, like a chain that extends,  \n",
      "To one, where it halts, and then back it descends.  \n",
      "\n",
      "In trees made of data, where branches spread wide,  \n",
      "Recursion traverses with grace as its guide.  \n",
      "From root to all leaves, in a depth-first delight,  \n",
      "Each call leads another, till the end comes in sight.  \n",
      "\n",
      "So fear not the depth, nor the loop that it weaves,  \n",
      "For inside its heart, a great wisdom achieves.  \n",
      "In programming's garden, let recursion take flight,  \n",
      "A maze of solutions, revealed in the night.  \n",
      "\n",
      "With elegance woven in each line of your script,  \n",
      "Let recursion befriend you, your logic equipped.  \n",
      "For in mirrors of function, the answers you hold,  \n",
      "In the dance of the codes, let the magic unfold.  \n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b9645d3-4ccc-46a1-a9aa-67fa444a9832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the realm of code where logic entwines,  \\nLives a concept, graceful, through layer it shines.  \\nA dance of function, in echo, it speaks,  \\nMeet recursion, the art that geeks seek.  \\n\\nA call to oneself, a mirror\\'s embrace,  \\nWhere solutions emerge from a self-repeating space.  \\nThe base case, the anchor, keeps chaos at bay,  \\nWithout it, dear coder, you\\'ll wander astray.  \\n\\nImagine a staircase, each step leads to more,  \\nYou climb higher and higher, through each open door.  \\nBut to find the solution, you must first take a glance,  \\nAt the single step down, in this intricate dance.  \\n\\nA factorial\\'s example, both simple and bright,  \\nFive factorial whispers, \"It\\'s four times my might!\"  \\nAnd four calls upon three, like a chain that extends,  \\nTo one, where it halts, and then back it descends.  \\n\\nIn trees made of data, where branches spread wide,  \\nRecursion traverses with grace as its guide.  \\nFrom root to all leaves, in a depth-first delight,  \\nEach call leads another, till the end comes in sight.  \\n\\nSo fear not the depth, nor the loop that it weaves,  \\nFor inside its heart, a great wisdom achieves.  \\nIn programming\\'s garden, let recursion take flight,  \\nA maze of solutions, revealed in the night.  \\n\\nWith elegance woven in each line of your script,  \\nLet recursion befriend you, your logic equipped.  \\nFor in mirrors of function, the answers you hold,  \\nIn the dance of the codes, let the magic unfold.  '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0b06b5c-72a9-44ab-b27f-7a983eba33b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She didn't go to the market.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  #model=\"gpt-3.5-turbo\",\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with statements, and your task is to convert them to standard English.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"She no went to the market.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.0,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0003f653-91e4-473b-b93d-3bc3f51e6ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM stands for \"Large Language Model.\" It refers to a type of artificial intelligence model that is trained on vast amounts of text data to understand and generate human language. These models utilize deep learning techniques, particularly neural networks, to predict the next word in a sentence, generate coherent text, answer questions, translate languages, and perform various other language-related tasks.\n",
      "\n",
      "Large language models leverage a transformer architecture, which allows them to recognize patterns in text and understand context effectively. Some well-known examples of LLMs include OpenAI's GPT (Generative Pre-trained Transformer) series and Google's BERT (Bidirectional Encoder Representations from Transformers).\n",
      "\n",
      "The \"large\" in LLM indicates that these models typically have millions or even billions of parameters, enabling them to capture complex relationships in language and generate more nuanced and contextually relevant responses. They are used in various applications, from chatbots and virtual assistants to content generation and sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is a LLM?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42c0ff9c-4db1-4772-b917-2e1273f70ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=185, prompt_tokens=23, total_tokens=208)\n"
     ]
    }
   ],
   "source": [
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f289ac40-995d-4e7b-8f1c-359ac3844ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020 World Series was played at Globe Life Field in Arlington, Texas. It was notable because it took place at a neutral site due to the COVID-19 pandemic.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ac804489-98a9-4114-9ab2-753156e254ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.chat.chat_completion.ChatCompletion'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4521057b-e8ed-49bb-9cfc-0546bf9c5c6b",
   "metadata": {},
   "source": [
    "## Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df094c78-c9ff-4ffe-92f8-4590917fede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Math Tutor\",\n",
    "  instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e7e9bf61-0ea8-4efb-808c-5621658f74a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Message](data=[Message(id='msg_ocqxxnygnQzvB6sTGZ3AIL2M', assistant_id='asst_w4AvFKIjrNzpAYG5Qb4fg4Ti', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"Of course, Jane Doe! Let's solve the equation step-by-step:\\n\\nGiven:\\n\\\\[ 3x + 11 = 14 \\\\]\\n\\n1. Subtract 11 from both sides to isolate the term with \\\\( x \\\\):\\n\\\\[ 3x + 11 - 11 = 14 - 11 \\\\]\\n\\\\[ 3x = 3 \\\\]\\n\\n2. Divide both sides by 3 to solve for \\\\( x \\\\):\\n\\\\[ \\\\frac{3x}{3} = \\\\frac{3}{3} \\\\]\\n\\\\[ x = 1 \\\\]\\n\\nSo, the solution to the equation \\\\( 3x + 11 = 14 \\\\) is \\\\( x = 1 \\\\).\"), type='text')], created_at=1721728917, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_ULRrPM5WlVGKrubUBjcgI0UF', status=None, thread_id='thread_o4Q02H4yUbYDm0vOhsBV4CNx'), Message(id='msg_HXVe5YeXTUZJ8CEhxfcuHsN2', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1721728100, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_o4Q02H4yUbYDm0vOhsBV4CNx')], object='list', first_id='msg_ocqxxnygnQzvB6sTGZ3AIL2M', last_id='msg_HXVe5YeXTUZJ8CEhxfcuHsN2', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "# Without streaming.\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")\n",
    "\n",
    "if run.status == 'completed': \n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "else:\n",
    "  print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f3e33631-d9f8-45ba-b686-2ff6121bb416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_to_txt(response):\n",
    "    import openai\n",
    "    \n",
    "    if isinstance(response, openai.types.chat.chat_completion.ChatCompletion):\n",
    "        return response.choices[0].message.content\n",
    "    elif isinstance(messages, openai.pagination.SyncCursorPage):\n",
    "        return response.data[0].content[0].text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d3bef542-885e-45c3-afe1-200a997cfc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course, Jane Doe! Let's solve the equation step-by-step:\n",
      "\n",
      "Given:\n",
      "\\[ 3x + 11 = 14 \\]\n",
      "\n",
      "1. Subtract 11 from both sides to isolate the term with \\( x \\):\n",
      "\\[ 3x + 11 - 11 = 14 - 11 \\]\n",
      "\\[ 3x = 3 \\]\n",
      "\n",
      "2. Divide both sides by 3 to solve for \\( x \\):\n",
      "\\[ \\frac{3x}{3} = \\frac{3}{3} \\]\n",
      "\\[ x = 1 \\]\n",
      "\n",
      "So, the solution to the equation \\( 3x + 11 = 14 \\) is \\( x = 1 \\).\n"
     ]
    }
   ],
   "source": [
    "print(response_to_txt(messages))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
